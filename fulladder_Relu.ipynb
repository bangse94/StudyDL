{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fulladder_Relu.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYFByUHq4BhV6JM/E0iP0I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bangse94/StudyDL/blob/main/fulladder_Relu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwf8pDlsrMw5",
        "outputId": "ebaf9aa2-e667-4b01-c3c0-515ec2463753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#full adder use ReLU function\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "lr = 0.1\n",
        "\n",
        "#trainning data & placeholder\n",
        "input_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]], dtype=np.float32)\n",
        "output_data = np.array([[0,0],[0,1],[0,1],[1,0],[0,1],[1,0],[1,0],[1,1]], dtype=np.float32)\n",
        "\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "#layer 1, 3 input 4 output\n",
        "W1 = tf.Variable(tf.random_normal([3, 4]), name=\"weight1\")\n",
        "b1 = tf.Variable(tf.random_normal([4]), name=\"bias1\")\n",
        "layer1 = tf.nn.leaky_relu(tf.matmul(X, W1) + b1)\n",
        "\n",
        "#layer 2, 4 input 2 output\n",
        "W2 = tf.Variable(tf.random_normal([4, 2]), name=\"weight2\")\n",
        "b2 = tf.Variable(tf.random_normal([2]), name=\"bias2\")\n",
        "hypothesis = tf.nn.leaky_relu(tf.matmul(layer1, W2) + b2)\n",
        "\n",
        "# cost function / minimize cost\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)\n",
        "\n",
        "# predicate / accuracy\n",
        "predicated = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicated, Y), dtype=tf.float32))\n",
        "\n",
        "#\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for step in range(10001):\n",
        "        sess.run(train, feed_dict={X: input_data, Y: output_data})\n",
        "        if step % 1000 == 0:\n",
        "            print(step, sess.run(cost, feed_dict={X: input_data, Y: output_data}), sess.run([W1, W2]))\n",
        "    h, c, a = sess.run([hypothesis, predicated, accuracy], feed_dict={X: input_data, Y: output_data})\n",
        "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "0 nan [array([[ 0.6659319 ,  1.2164893 , -0.4145603 , -0.80205494],\n",
            "       [-1.5401095 ,  0.92698693, -0.9159724 ,  0.46596813],\n",
            "       [-0.76177156, -0.3033453 ,  0.19560932,  0.57966685]],\n",
            "      dtype=float32), array([[-1.0800066 ,  0.02427298],\n",
            "       [-0.97281325,  0.54063463],\n",
            "       [ 0.20543152, -0.1656028 ],\n",
            "       [-0.07444689, -0.4009994 ]], dtype=float32)]\n",
            "1000 nan [array([[ 3.296899  ,  0.72369254, -0.38065097, -4.853016  ],\n",
            "       [-3.4223895 , -0.07398673, -0.9112069 ,  7.0747476 ],\n",
            "       [-2.7856874 , -1.3043576 ,  0.19858885,  7.2392955 ]],\n",
            "      dtype=float32), array([[-3.5519021e+00,  3.9792922e+00],\n",
            "       [-1.0476868e+00,  1.0273120e+00],\n",
            "       [-3.5223269e-01,  6.3699884e-03],\n",
            "       [ 8.8962231e+00, -8.5432043e+00]], dtype=float32)]\n",
            "2000 nan [array([[ 4.4724245 ,  0.77165407, -0.37196842, -7.1758113 ],\n",
            "       [-4.1695733 , -0.14447036, -0.9237712 , 10.516402  ],\n",
            "       [-3.53715   , -1.3749357 ,  0.18601422, 10.685407  ]],\n",
            "      dtype=float32), array([[ -4.6988707 ,   5.136807  ],\n",
            "       [ -1.1463552 ,   1.1281428 ],\n",
            "       [ -0.38481942,   0.04017637],\n",
            "       [ 12.907699  , -12.634531  ]], dtype=float32)]\n",
            "3000 nan [array([[ 5.4291196 ,  0.80660087, -0.36524928, -8.809126  ],\n",
            "       [-4.69822   , -0.187468  , -0.9318719 , 13.146683  ],\n",
            "       [-4.0673647 , -1.417946  ,  0.17791359, 13.316406  ]],\n",
            "      dtype=float32), array([[ -5.589194  ,   6.016402  ],\n",
            "       [ -1.2025313 ,   1.1857476 ],\n",
            "       [ -0.4005088 ,   0.05696347],\n",
            "       [ 15.9879055 , -15.754195  ]], dtype=float32)]\n",
            "4000 nan [array([[  6.29193   ,   0.8356149 ,  -0.35957772, -10.18257   ],\n",
            "       [ -5.125323  ,  -0.21868461,  -0.93785423,  15.350334  ],\n",
            "       [ -4.495338  ,  -1.4491627 ,   0.17193222,  15.520065  ]],\n",
            "      dtype=float32), array([[ -6.3662424 ,   6.7779975 ],\n",
            "       [ -1.2413043 ,   1.2255722 ],\n",
            "       [ -0.40964085,   0.06699108],\n",
            "       [ 18.57412   , -18.366005  ]], dtype=float32)]\n",
            "5000 nan [array([[  7.067631  ,   0.85981077,  -0.35482094, -11.39233   ],\n",
            "       [ -5.4929385 ,  -0.24336447,  -0.94261664,  17.286291  ],\n",
            "       [ -4.8635416 ,  -1.4738406 ,   0.16717067,  17.45584   ]],\n",
            "      dtype=float32), array([[ -7.0572987 ,   7.4533377 ],\n",
            "       [ -1.2713743 ,   1.2564343 ],\n",
            "       [ -0.416147  ,   0.07420357],\n",
            "       [ 20.849117  , -20.659542  ]], dtype=float32)]\n",
            "6000 nan [array([[  7.774328  ,   0.88048595,  -0.35074738, -12.48448   ],\n",
            "       [ -5.8201294 ,  -0.26385465,  -0.9465846 ,  19.033527  ],\n",
            "       [ -5.1911774 ,  -1.494328  ,   0.16320358,  19.20285   ]],\n",
            "      dtype=float32), array([[ -7.68365   ,   8.064974  ],\n",
            "       [ -1.2961186 ,   1.281789  ],\n",
            "       [ -0.42124572,   0.07986317],\n",
            "       [ 22.9042    , -22.728954  ]], dtype=float32)]\n",
            "7000 nan [array([[  8.426277  ,   0.8985355 ,  -0.34718862, -13.490276  ],\n",
            "       [ -6.1175556 ,  -0.28141826,  -0.9499925 ,  20.63842   ],\n",
            "       [ -5.4889593 ,  -1.511889  ,   0.15979633,  20.807487  ]],\n",
            "      dtype=float32), array([[ -8.259738  ,   8.627599  ],\n",
            "       [ -1.3172289 ,   1.3033841 ],\n",
            "       [ -0.42546228,   0.08453249],\n",
            "       [ 24.793074  , -24.629332  ]], dtype=float32)]\n",
            "8000 nan [array([[  9.033852  ,   0.91456574,  -0.34402806, -14.426434  ],\n",
            "       [ -6.3919034 ,  -0.2968162 ,  -0.9529835 ,  22.13092   ],\n",
            "       [ -5.7635927 ,  -1.5272846 ,   0.15680571,  22.29975   ]],\n",
            "      dtype=float32), array([[ -8.795549  ,   9.15118   ],\n",
            "       [ -1.3356898 ,   1.3222356 ],\n",
            "       [ -0.42907047,   0.08851284],\n",
            "       [ 26.550562  , -26.396368  ]], dtype=float32)]\n",
            "9000 nan [array([[  9.546244  ,   0.9291297 ,  -0.341158  , -15.304114  ],\n",
            "       [ -6.7105527 ,  -0.31053552,  -0.955651  ,  23.530918  ],\n",
            "       [ -6.0824895 ,  -1.541001  ,   0.15413922,  23.69951   ]],\n",
            "      dtype=float32), array([[ -9.300802  ,   9.645395  ],\n",
            "       [ -1.3520557 ,   1.3389227 ],\n",
            "       [ -0.4321602 ,   0.09191252],\n",
            "       [ 28.19992   , -28.053764  ]], dtype=float32)]\n",
            "10000 nan [array([[ 10.030589  ,   0.94263196,  -0.338501  , -16.134413  ],\n",
            "       [ -7.01947   ,  -0.3229105 ,  -0.9580571 ,  24.852694  ],\n",
            "       [ -6.3916173 ,  -1.5533739 ,   0.15173417,  25.021086  ]],\n",
            "      dtype=float32), array([[ -9.7831335 ,  10.117825  ],\n",
            "       [ -1.366701  ,   1.3538373 ],\n",
            "       [ -0.4347822 ,   0.09479561],\n",
            "       [ 29.757902  , -29.618612  ]], dtype=float32)]\n",
            "\n",
            "Hypothesis:  [[ 450.21136   -88.88563 ]\n",
            " [1234.2507   -245.26494 ]\n",
            " [1230.2284   -244.4591  ]\n",
            " [1987.7207   -395.34738 ]\n",
            " [ -25.654749  135.18736 ]\n",
            " [ 679.24274  -134.1979  ]\n",
            " [ 680.1343   -134.40846 ]\n",
            " [1487.6506   -295.64383 ]] \n",
            "Correct:  [[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]] \n",
            "Accuracy:  0.625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}